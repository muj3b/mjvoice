<div align="center">

# ğŸ¤ **mjvoice**

**Privacyâ€‘first, AIâ€‘powered dictation for macOS with a liquidâ€‘glass HUD**

<p align="center">
  <a href="https://developer.apple.com/macos/"><img alt="macOS" src="https://img.shields.io/badge/macOS-13%2B-black?style=for-the-badge&logo=apple&logoColor=white"></a>
  <a href="https://swift.org/"><img alt="Swift" src="https://img.shields.io/badge/Swift-5.9-FA7343?style=for-the-badge&logo=swift&logoColor=white"></a>
  <img alt="Build" src="https://img.shields.io/badge/Build-Beta-lightgrey?style=for-the-badge&logo=xcode&logoColor=white">
  <img alt="Privacy" src="https://img.shields.io/badge/Offline-First-2ea44f?style=for-the-badge&logo=shield"></a>
</p>

<h3 align="center">
  <code>git clone &lt;YOUR_REPO_URL&gt; && cd mjvoice && open mjvoice.xcodeproj</code>
</h3>

</div>

---

## ğŸ§­ Table of Contents

* [Highlights](#-highlights)
* [Demo](#-demo)
* [Why mjvoice?](#-why-mjvoice)
* [Performance Benchmarks](#-performance-benchmarks)
* [Core Features](#-core-features)
* [Installation](#-installation)
* [Usage Guide](#-usage-guide)
* [Architecture](#-architecture)
* [Development](#-development)
* [Performance Optimization](#-performance-optimization)
* [Troubleshooting](#-troubleshooting)
* [Privacy & Security](#-privacy--security)
* [Roadmap](#-roadmap)
* [License](#-license)
* [Acknowledgments](#-acknowledgments)

---

## ğŸŒŸ Highlights

* **Zero cloud** by default â€” offline ASR with CoreML or local Python runtime
* **Liquidâ€‘glass HUD** overlay with waveform and status states
* **Pushâ€‘toâ€‘talk** modes: pressâ€‘hold, latch, toggle
* **Smart formatting**: filler removal, punctuation, tone presets
* **Systemâ€‘wide insertion** via Accessibility API (clipboard fallback)

> â„¹ï¸ This README avoids dead links.
> Paths like `Docs/â€¦` assume files exist in this repo. Replace `&lt;YOUR_REPO_URL&gt;` with your actual Git URL.

---

## ğŸ¬ Demo

<details open>
<summary><strong>â–¶ Show demo media</strong></summary>

* **GIF/MP4 (recommended):** `Docs/images/demo.gif` or `Docs/videos/demo.mp4`
* **What to show:** hotkey â†’ HUD appears â†’ speak â†’ formatted text inserted

```html
<!-- Fallback markup: shows image if GIF exists, otherwise nothing -->
<picture>
  <source srcset="Docs/videos/demo.mp4" type="video/mp4">
  <img src="Docs/images/demo.gif" alt="mjvoice demo (HUD + transcription)">
</picture>
```

</details>

> Example transformation block:
>
> ```
> BEFORE: "um hey can you uh send me that file like right now"
> AFTER:  "Hey, can you send me that file right now?"
> âš¡ Latency sample: 147 ms â€¢ ğŸ”’ 100% offline
> ```

---

## âš¡ Why mjvoice?

<div style="display:flex;gap:16px;flex-wrap:wrap">

<div style="flex:1;min-width:280px">

### ğŸš€ Instant Response

```text
Hotkey â”€â”€â–º Recording (VAD)
          â†“  ~80â€“120 ms
Transcribe â”€â”€â–º Format â”€â”€â–º Insert
          â†“  ~30â€“60 ms each stage
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Typical total: 110â€“180 ms
```

**Often faster than typing** for short phrases and quick replies.

</div>

<div style="flex:1;min-width:280px">

### ğŸ” Privacy Fortress

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           YOUR MAC           â”‚
â”‚  Audio â†’ VAD â†’ ASR â†’ Format  â”‚
â”‚           â†’ Insert           â”‚
â”‚                              â”‚
â”‚  âŒ No cloud  âŒ Telemetry    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**No data leaves your device** by default.

</div>

</div>

---

## ğŸ“Š Performance Benchmarks

<details open>
<summary><strong>Internal test snapshots on Mâ€‘series Mac</strong></summary>

> Numbers below mirror the projectâ€™s example benchmarks and are **for guidance**; your results will vary by hardware and model size.

| Engine                   | Cold Start | Warm Start | Proc. Cost (per audio min) | Memory | Est. Battery Impact | WER* | Verdict          |
| ------------------------ | ---------: | ---------: | -------------------------: | -----: | ------------------: | ---: | ---------------- |
| WhisperKit **tiny**      |     187 ms |      67 ms |                     347 ms |  28 MB |              âˆ’12 mW | 8.2% | âš¡ Mobile/battery |
| WhisperKit **small**     |     312 ms |      94 ms |                     687 ms |  89 MB |              âˆ’28 mW | 4.1% | ğŸ¯ Balanced      |
| Fluid *(fasterâ€‘whisper)* |    1247 ms |     234 ms |                     912 ms | 312 MB |              âˆ’45 mW | 2.8% | ğŸ† Max accuracy  |

*WER = Word Error Rate (lower is better)

</details>

---

## ğŸ¯ Core Features

### ğŸ™ï¸ Pushâ€‘toâ€‘Talk Modes

| Mode           | Visual                  | Best For                                 |
| -------------- | ----------------------- | ---------------------------------------- |
| **Pressâ€‘Hold** | `â¬‡ï¸ press â€¦ â¬†ï¸ release` | Bursts (2â€“15 s): chats, searches         |
| **Latch**      | `tap â–¶ recording â–¶ tap` | Replies (15â€“60 s): emails, docs          |
| **Toggle**     | `on â€¦ off`              | Long dictation (â‰¥1 min): notes, articles |

### ğŸ¤– AI Text Transformation

<details>
<summary><strong>Click for examples</strong></summary>

```diff
INPUT:  "um so like I think we should uh maybe consider you know the alternatives"
- filler words removed
+ capitalization & punctuation
OUTPUT: "So I think we should maybe consider the alternatives."
```

```diff
INPUT:  "connect to postgres database using node j s"
+ technical capitalization
OUTPUT: "Connect to PostgreSQL database using Node.js."
```

</details>

### ğŸ¨ Liquidâ€‘Glass HUD States

```
IDLE  â†’ LISTENING (waveform) â†’ THINKING (spinner) â†’ SUCCESS âœ“ / ERROR âœ— / SECURE ğŸ”’
```

### ğŸ“Š Engine Matrix

| Feature    | WhisperKit (tiny) | WhisperKit (small) | Fluid (fasterâ€‘whisper) |
| ---------- | :---------------: | :----------------: | :--------------------: |
| Accuracy   |       â­â­â­â˜†â˜†       |        â­â­â­â­â˜†       |          â­â­â­â­â­         |
| Speed      |       â­â­â­â­â­       |        â­â­â­â­â˜†       |          â­â­â­â˜†â˜†         |
| Battery    |       â­â­â­â­â­       |        â­â­â­â­â˜†       |          â­â­â˜†â˜†â˜†         |
| Memory     |       28 MB       |        89 MB       |         312 MB         |
| Cold Start |       187 ms      |       312 ms       |         1247 ms        |
| WER        |        8.2%       |        4.1%        |          2.8%          |
| Best Use   |       Mobile      |       Desktop      |       Pluggedâ€‘in       |

> ğŸ’¡ **Adaptive Mode** can autoâ€‘switch engines based on power/thermals.

---

## ğŸ“¦ Installation

### âœ… Requirements

| Component | Minimum                                | Notes                  |
| --------- | -------------------------------------- | ---------------------- |
| macOS     | 13.0+ (Ventura/Sonoma/Sequoia)         |                        |
| CPU       | Apple Silicon (M1/M2/M3) or Intel AVX2 | Mâ€‘series recommended   |
| RAM       | 8 GB (16 GB recommended)               |                        |
| Storage   | 2 GB free                              | Models + runtime       |
| Xcode     | 15+ (CLT installed)                    | Build from source      |
| Python    | 3.8+                                   | Optional; Fluid engine |

### ğŸš€ Quick Start

<details open>
<summary><strong>Build from source</strong></summary>

```bash
# 1) Clone (replace with your repo URL)
git clone <YOUR_REPO_URL>
cd mjvoice

# 2) (Optional) Generate project from XcodeGen
xcodegen --spec project.yml

# 3) Open in Xcode
open mjvoice.xcodeproj

# 4) Configure Signing (Xcode â†’ Signing & Capabilities)

# 5) Build & Run (âŒ˜R)
```

See `Docs/BUILD.md` for details.

</details>

### ğŸ” Permissions

* **Microphone** â†’ autoâ€‘prompted on first run
* **Accessibility** â†’ System Settings â–¸ Privacy & Security â–¸ Accessibility â–¸ add **mjvoice** (âœ… checked)
* **Notifications (optional)** â†’ for clipboard fallback alerts

### ğŸ“¥ Model Installation

* **Automatic (recommended):** first use downloads CoreML Whisper models with checksum & resume.
* **Manual:** place `.mlmodelc` under `~/Library/Application Support/mjvoice/Models/`.
* **Fluid runtime:** Preferences â–¸ Advanced â–¸ *Install Fluid Runtime* (creates `~/.mjvoice/fluid/`).

---

## ğŸ“ Usage Guide

### âŒ¨ï¸ Hotkeys

* Default: **Fn** (Globe) â€” supports pressâ€‘hold, latch, toggle
* Alternate: **âŒ˜âŒ¥Space** or any custom combo (Preferences â–¸ General)

### Modes

<details>
<summary><strong>Streaming (realâ€‘time)</strong></summary>

Low latency (<200 ms/word). May show partials briefly.

</details>

<details>
<summary><strong>Instant (buffered)</strong></summary>

Buffers a breathâ€‘pause (~0.5â€“0.8 s) â†’ cleaner punctuation.

</details>

<details>
<summary><strong>Notes Mode (scratchpad)</strong></summary>

Persistent window for brainstorming; export when ready.

</details>

### âœ¨ Smart Formatting

* **Tone presets:** neutral / professional / friendly
* **Perâ€‘app presets:** Mail, Slack, VS Code, etc. via dashboard
* **Custom dictionary:** import CSV of technical terms

```yaml
Mail.app:
  tone: professional
  remove_fillers: true
  auto_capitalize: true
  punctuation: full
```

---

## ğŸ—ï¸ Architecture

### Highâ€‘level flow (Mermaid)

```mermaid
flowchart LR
  A[Hotkey] --> B[VAD Gate]
  B -->|speech| C[ASR Engine]
  C --> D[LLM Formatter]
  D --> E[Text Insertion]
  B -.->|silence| F[(discard)]
  subgraph Local Only
    B
    C
    D
    E
  end
```

### Components

* **Main App (SwiftUI):** menu bar UI, settings, orchestration
* **XPC services:** `AudioVADService`, `ASRService`, `LLMService` (sandboxed, autoâ€‘unload)
* **Output layer:** Accessibility API â†’ clipboard fallback â†’ Notes window
* **Storage:** `~/Library/Application Support/mjvoice/` (preferences, snippets, usage, models)

---

## ğŸ› ï¸ Development

### Project Structure

```text
mjvoice/
â”œâ”€ mjvoice/ (SwiftUI app)
â”œâ”€ Shared/ (models, utils, protocols, resources)
â”œâ”€ Workers/ (XPC: AudioVAD, ASR, LLM)
â”œâ”€ Tests/ (unit + integration)
â”œâ”€ Docs/ (BUILD.md, PERFORMANCE.md, PRIVACY.md, USER_GUIDE.md, images/)
â””â”€ tools/ (install scripts, model downloads, signing)
```

### XcodeGen

```bash
brew install xcodegen
xcodegen && open mjvoice.xcodeproj
```

### SwiftPM (example)

```swift
// Package.swift (conceptual)
.dependencies = [
  .package(url: "https://github.com/argmaxinc/WhisperKit.git", from: "0.5.0"),
  // VAD, utilities, etc.
]
```

---

## âš¡ Performance Optimization

* **Speed:** WhisperKit *tiny*, streaming mode, minimal formatting
* **Battery:** Adaptive mode on battery, tiny model, XPC autoâ€‘unload (5 s)
* **Memory caps:** short audio buffers, lazy model load, limit transcript history

Target metrics snapshot (typical): idle RAM â‰¤30 MB app; hotkey response 67â€“92 ms; streaming latency 110â€“189 ms.

---

## ğŸ§¯ Troubleshooting (quick picks)

* **No text insertion?** Check Accessibility permission â–¸ enable **mjvoice**; try clipboard fallback.
* **No audio?** Verify Microphone permission and input device in macOS Sound settings.
* **Fluid errors?** Reâ€‘install runtime from Preferences â–¸ Advanced; ensure Python â‰¥3.8.
* **Hotkey conflict?** Try **âŒ˜âŒ¥âŒƒD** or rebind Spotlight away from **âŒ˜Space**.

See `Docs/USER_GUIDE.md#troubleshooting` for deepâ€‘dive steps & logs.

---

## ğŸ” Privacy & Security

* **Offlineâ€‘first:** ASR + formatting performed locally
* **Zero telemetry:** no analytics/crash reports sent
* **Sandboxed XPC:** leastâ€‘privilege services
* **Secureâ€‘input aware:** pauses in password fields
* **Data at rest:** JSON in `~/Library/Application Support/mjvoice/` under your control

Data summary:

| Data          |  Stored  | Where        |      Network     |
| ------------- | :------: | ------------ | :--------------: |
| Audio buffers | RAMâ€‘only | ephemeral    |         âŒ        |
| Transcripts   |     âœ…    | local JSON   |         âŒ        |
| Preferences   |     âœ…    | local JSON   |         âŒ        |
| Models        |     âœ…    | local folder | â¬‡ï¸ download only |

---

## ğŸ—ºï¸ Roadmap

* **v1.0:** PTT modes, WhisperKit/Fluid engines, HUD, snippets, perâ€‘app presets, adaptive mode, XPC architecture
* **v1.1 (planned):** transcript window, multilingual support, autoâ€‘language detect, better noise suppression
* **v1.2 (planned):** voice editing commands, macros, custom grammars

---

## ğŸ“„ License

**Status:** *TBD by project maintainers.* Until finalized, treat source as All Rights Reserved or per repository LICENSE once added.

> Recommendation: choose **MIT** (simple/permissive) or **Apacheâ€‘2.0** (patent grant). Add `LICENSE` before publishing binaries.

---

## ğŸ™ Acknowledgments

* **WhisperKit (Argmax)** â€” CoreML Whisper integration
* **Silero VAD** â€” voice activity detection
* **fasterâ€‘whisper (SYSTRAN)** â€” optimized Whisper inference
* **dtlnâ€‘rs** â€” realâ€‘time noise suppression

---

<div align="center">

### ğŸŒŸ Built with â¤ï¸ for the macOS community

If this project helps your workflow, consider starring the repo once itâ€™s public.

</div>